# =============================================================================
# PistonProtection - Local Development Docker Compose
# =============================================================================
#
# Usage:
#   docker compose up -d                    # Start all services
#   docker compose up -d --build            # Rebuild and start
#   docker compose logs -f gateway          # View gateway logs
#   docker compose down -v                  # Stop and remove volumes
#
# Access:
#   Frontend:      http://localhost:3000
#   Gateway API:   http://localhost:8080
#   Grafana:       http://localhost:3001 (admin/admin)
#   Prometheus:    http://localhost:9099
#   Tempo:         http://localhost:3200
#   Loki:          http://localhost:3100
#   ClickHouse:    http://localhost:8123
#   Alertmanager:  http://localhost:9093
#   Alloy UI:      http://localhost:12345
#
# Observability Stack Versions (Updated January 2026):
#   Prometheus:    3.2.1  (with OTLP receiver support)
#   Grafana:       12.3.0 (with new drilldown features)
#   Loki:          3.6.3  (with pattern ingester)
#   Tempo:         2.9.0  (with vParquet4 format)
#   Alloy:         1.12.2 (replaces deprecated Grafana Agent)
#   OTEL Collector: 0.143.1 (with ClickHouse exporter)
#   ClickHouse:    25.12.2 (for event analytics)
#   Alertmanager:  0.28.0
#
# =============================================================================

name: pistonprotection

services:
  # ===========================================================================
  # Core Services
  # ===========================================================================

  gateway:
    build:
      context: .
      dockerfile: docker/gateway/Dockerfile
    container_name: pp-gateway
    ports:
      - "8080:8080"   # HTTP API
      - "9090:9090"   # gRPC API
      - "9091:9091"   # Metrics
    environment:
      RUST_LOG: info,pistonprotection=debug
      DATABASE_URL: postgres://pistonprotection:pistonprotection@postgres:5432/pistonprotection
      REDIS_URL: redis://redis:6379
      CONFIG_MGR_URL: http://config-mgr:8080
      AUTH_SERVICE_URL: http://auth:8080
      METRICS_SERVICE_URL: http://metrics:8080
      OTEL_EXPORTER_OTLP_ENDPOINT: http://otel-collector:4317
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      config-mgr:
        condition: service_started
    networks:
      - pistonprotection
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    restart: unless-stopped

  worker:
    build:
      context: .
      dockerfile: docker/worker/Dockerfile
    container_name: pp-worker
    ports:
      - "8081:8080"   # HTTP API
      - "9092:9091"   # Metrics
    environment:
      RUST_LOG: info,pistonprotection=debug
      REDIS_URL: redis://redis:6379
      CONFIG_MGR_URL: http://config-mgr:8080
      GATEWAY_URL: http://gateway:9090
      EBPF_PROGRAMS_PATH: /opt/pistonprotection/ebpf
      OTEL_EXPORTER_OTLP_ENDPOINT: http://otel-collector:4317
    # Required for eBPF
    privileged: true
    cap_add:
      - NET_ADMIN
      - SYS_ADMIN
      - BPF
    depends_on:
      redis:
        condition: service_healthy
      config-mgr:
        condition: service_started
    networks:
      - pistonprotection
    volumes:
      - /sys/fs/bpf:/sys/fs/bpf:rw
      - /sys/kernel/debug:/sys/kernel/debug:ro
    restart: unless-stopped

  config-mgr:
    build:
      context: .
      dockerfile: docker/config-mgr/Dockerfile
    container_name: pp-config-mgr
    ports:
      - "8082:8080"   # HTTP API
      - "9093:9091"   # Metrics
    environment:
      RUST_LOG: info,pistonprotection=debug
      DATABASE_URL: postgres://pistonprotection:pistonprotection@postgres:5432/pistonprotection
      REDIS_URL: redis://redis:6379
      CONFIG_DATA_DIR: /var/lib/pistonprotection/config
      OTEL_EXPORTER_OTLP_ENDPOINT: http://otel-collector:4317
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - pistonprotection
    volumes:
      - config-data:/var/lib/pistonprotection/config
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s
    restart: unless-stopped

  metrics:
    build:
      context: .
      dockerfile: docker/metrics/Dockerfile
    container_name: pp-metrics
    ports:
      - "8083:8080"   # HTTP API
      - "9094:9091"   # Prometheus metrics
    environment:
      RUST_LOG: info,pistonprotection=debug
      DATABASE_URL: postgres://pistonprotection:pistonprotection@postgres:5432/pistonprotection
      REDIS_URL: redis://redis:6379
      METRICS_DATA_DIR: /var/lib/pistonprotection/metrics
      OTEL_EXPORTER_OTLP_ENDPOINT: http://otel-collector:4317
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - pistonprotection
    volumes:
      - metrics-data:/var/lib/pistonprotection/metrics
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s
    restart: unless-stopped

  auth:
    build:
      context: .
      dockerfile: docker/auth/Dockerfile
    container_name: pp-auth
    ports:
      - "8084:8080"   # HTTP API
      - "9095:9091"   # Metrics
    environment:
      RUST_LOG: info,pistonprotection=debug
      DATABASE_URL: postgres://pistonprotection:pistonprotection@postgres:5432/pistonprotection
      REDIS_URL: redis://redis:6379
      JWT_SECRET: dev-jwt-secret-change-in-production
      AUTH_DATA_DIR: /var/lib/pistonprotection/auth
      OTEL_EXPORTER_OTLP_ENDPOINT: http://otel-collector:4317
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - pistonprotection
    volumes:
      - auth-data:/var/lib/pistonprotection/auth
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s
    restart: unless-stopped

  frontend:
    build:
      context: .
      dockerfile: docker/frontend/Dockerfile
      args:
        API_URL: http://gateway:8080
    container_name: pp-frontend
    ports:
      - "3000:8080"
    environment:
      API_URL: http://gateway:8080
    depends_on:
      - gateway
    networks:
      - pistonprotection
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    restart: unless-stopped

  # ===========================================================================
  # Infrastructure Services
  # ===========================================================================

  postgres:
    image: postgres:16-alpine
    container_name: pp-postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: pistonprotection
      POSTGRES_PASSWORD: pistonprotection
      POSTGRES_DB: pistonprotection
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init.sql:ro
    networks:
      - pistonprotection
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U pistonprotection -d pistonprotection"]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 10s
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    container_name: pp-redis
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    volumes:
      - redis-data:/data
    networks:
      - pistonprotection
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 5s
    restart: unless-stopped

  # ===========================================================================
  # Observability Stack
  # ===========================================================================

  prometheus:
    image: prom/prometheus:v3.2.1
    container_name: pp-prometheus
    ports:
      - "9099:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=7d'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
      - '--web.enable-remote-write-receiver'
      - '--enable-feature=otlp-write-receiver'
    volumes:
      - ./observability/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./observability/prometheus/alerts.yaml:/etc/prometheus/alerts.yaml:ro
      - prometheus-data:/prometheus
    networks:
      - pistonprotection
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9090/-/healthy"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped

  grafana:
    image: grafana/grafana:12.3.0
    container_name: pp-grafana
    ports:
      - "3001:3000"
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
      GF_USERS_ALLOW_SIGN_UP: "false"
      GF_INSTALL_PLUGINS: grafana-clock-panel,grafana-clickhouse-datasource
      GF_DASHBOARDS_DEFAULT_HOME_DASHBOARD_PATH: /var/lib/grafana/dashboards/traffic-overview.json
      GF_FEATURE_TOGGLES_ENABLE: traceqlEditor,correlations,newTraceViewHeader,traceToMetrics
    volumes:
      - ./observability/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./observability/grafana/dashboards:/var/lib/grafana/dashboards:ro
      - grafana-data:/var/lib/grafana
    networks:
      - pistonprotection
    depends_on:
      - prometheus
      - loki
      - tempo
      - clickhouse
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://localhost:3000/api/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
    restart: unless-stopped

  loki:
    image: grafana/loki:3.6.3
    container_name: pp-loki
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - ./observability/loki/loki-config.yaml:/etc/loki/local-config.yaml:ro
      - loki-data:/loki
    networks:
      - pistonprotection
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://localhost:3100/ready || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 15s
    restart: unless-stopped

  # Grafana Alloy - unified telemetry collector (replaces deprecated Promtail/Agent)
  # Grafana Agent reached EOL on November 1, 2025 - Alloy is the recommended replacement
  alloy:
    image: grafana/alloy:v1.12.2
    container_name: pp-alloy
    ports:
      - "12345:12345"  # Alloy UI and health
      - "4319:4317"    # OTLP gRPC (for direct log ingestion)
    volumes:
      - ./observability/alloy/config.alloy:/etc/alloy/config.alloy:ro
      - /var/log:/var/log:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - alloy-data:/var/lib/alloy
    command:
      - run
      - /etc/alloy/config.alloy
      - --storage.path=/var/lib/alloy
      - --server.http.listen-addr=0.0.0.0:12345
      - --stability.level=generally-available
    networks:
      - pistonprotection
    depends_on:
      - loki
      - prometheus
      - tempo
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:12345/ready"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 15s
    restart: unless-stopped

  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.143.1
    container_name: pp-otel-collector
    ports:
      - "4317:4317"   # OTLP gRPC
      - "4318:4318"   # OTLP HTTP
      - "8888:8888"   # Prometheus metrics exposed by the collector
      - "8889:8889"   # Prometheus exporter metrics
      - "13133:13133" # Health check
    volumes:
      - ./observability/otel/otel-collector-config.yaml:/etc/otel-collector-config.yaml:ro
    command: ["--config=/etc/otel-collector-config.yaml"]
    networks:
      - pistonprotection
    depends_on:
      - prometheus
      - loki
      - tempo
      - clickhouse
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:13133/"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 15s
    restart: unless-stopped

  # Grafana Tempo - Distributed tracing backend
  tempo:
    image: grafana/tempo:2.9.0
    container_name: pp-tempo
    ports:
      - "3200:3200"   # Tempo HTTP API
      - "9095:9095"   # Tempo gRPC
      - "4320:4317"   # OTLP gRPC receiver
      - "4321:4318"   # OTLP HTTP receiver
      - "14268:14268" # Jaeger ingest
      - "9411:9411"   # Zipkin ingest
    command: ["-config.file=/etc/tempo/tempo-config.yaml"]
    volumes:
      - ./observability/tempo/tempo-config.yaml:/etc/tempo/tempo-config.yaml:ro
      - tempo-data:/tmp/tempo
    networks:
      - pistonprotection
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:3200/ready"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 15s
    restart: unless-stopped

  # ClickHouse - High-performance analytics database for event storage
  clickhouse:
    image: clickhouse/clickhouse-server:25.12.2
    container_name: pp-clickhouse
    ports:
      - "8123:8123"   # HTTP interface
      - "9000:9000"   # Native TCP interface
    environment:
      CLICKHOUSE_DB: pistonprotection
      CLICKHOUSE_USER: pistonprotection
      CLICKHOUSE_PASSWORD: pistonprotection
      CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1
    volumes:
      - ./observability/clickhouse/config.xml:/etc/clickhouse-server/config.d/custom.xml:ro
      - ./observability/clickhouse/users.xml:/etc/clickhouse-server/users.d/custom.xml:ro
      - ./observability/clickhouse/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
      - clickhouse-data:/var/lib/clickhouse
      - clickhouse-logs:/var/log/clickhouse-server
    networks:
      - pistonprotection
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8123/ping"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
    restart: unless-stopped

  # Alertmanager - Alert routing and management
  alertmanager:
    image: prom/alertmanager:v0.28.0
    container_name: pp-alertmanager
    ports:
      - "9093:9093"
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--web.external-url=http://localhost:9093'
    volumes:
      - ./observability/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
      - alertmanager-data:/alertmanager
    networks:
      - pistonprotection
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9093/-/healthy"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped

  # ===========================================================================
  # Development Tools
  # ===========================================================================

  # pgAdmin for database management
  pgadmin:
    image: dpage/pgadmin4:8
    container_name: pp-pgadmin
    ports:
      - "5050:80"
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@pistonprotection.local
      PGADMIN_DEFAULT_PASSWORD: admin
      PGADMIN_CONFIG_SERVER_MODE: "False"
    volumes:
      - pgadmin-data:/var/lib/pgadmin
    networks:
      - pistonprotection
    depends_on:
      - postgres
    profiles:
      - tools
    restart: unless-stopped

  # Redis Commander for Redis management
  redis-commander:
    image: rediscommander/redis-commander:latest
    container_name: pp-redis-commander
    ports:
      - "8085:8081"
    environment:
      REDIS_HOSTS: local:redis:6379
    networks:
      - pistonprotection
    depends_on:
      - redis
    profiles:
      - tools
    restart: unless-stopped

  # Mailhog for email testing
  mailhog:
    image: mailhog/mailhog:latest
    container_name: pp-mailhog
    ports:
      - "1025:1025"   # SMTP
      - "8025:8025"   # Web UI
    networks:
      - pistonprotection
    profiles:
      - tools
    restart: unless-stopped

# =============================================================================
# Networks
# =============================================================================

networks:
  pistonprotection:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16

# =============================================================================
# Volumes
# =============================================================================

volumes:
  postgres-data:
    driver: local
  redis-data:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
  loki-data:
    driver: local
  tempo-data:
    driver: local
  clickhouse-data:
    driver: local
  clickhouse-logs:
    driver: local
  alertmanager-data:
    driver: local
  alloy-data:
    driver: local
  config-data:
    driver: local
  metrics-data:
    driver: local
  auth-data:
    driver: local
  pgadmin-data:
    driver: local
